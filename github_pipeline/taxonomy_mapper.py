"""
Taxonomy Mapper - åˆ†ç±»æ˜ å°„å™¨
åŠŸèƒ½ï¼šæ ¹æ® description, topics, language æ¨æ–­ task, categories, data_types
"""

import re
from github_pipeline.taxonomy_schema import (
    TASKS,
    DATA_TYPES,
    CATEGORIES,
    get_data_type_for_task,
    get_categories_for_task
)



# ===== å…³é”®è¯æ˜ å°„ =====
TASK_KEYWORDS = {
    # NLP
    "text-generation": ["gpt", "llm", "language model", "text generation", "generative", "transformer"],
    "text-classification": ["classification", "sentiment", "bert", "roberta"],
    "translation": ["translation", "translate", "multilingual"],
    "summarization": ["summarization", "summary"],
    
    # Vision  
    "object-detection": ["yolo", "detection", "detect", "rcnn", "object detection"],
    "image-segmentation": ["segmentation", "segment", "mask", "sam", "semantic segmentation"],
    "image-classification": ["image classification", "resnet", "vit", "imagenet"],
    
    # å…¶ä»–
    "reinforcement-learning": ["reinforcement", "rl", "policy"],
}


def find_task_from_text(text):
    """
    ä»æ–‡æœ¬ä¸­æ‰¾åˆ°æœ€åŒ¹é…çš„ä»»åŠ¡
    
    å‚æ•°:
        text: ç»„åˆçš„æ–‡æœ¬ï¼ˆdescription + topicsï¼‰
    
    è¿”å›:
        str: ä»»åŠ¡åç§°ï¼Œå¦‚ "text-generation"
    """
    text_lower = text.lower()
    
    # æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„å…³é”®è¯
    for task, keywords in TASK_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text_lower:
                return task
    
    return "unknown"


def map_taxonomy(model):
    """
    ä¸ºå•ä¸ªæ¨¡å‹æ·»åŠ åˆ†ç±»ä¿¡æ¯
    
    è¾“å…¥æ ¼å¼ï¼ˆGitHubï¼‰ï¼š
    {
        "modelId": "karpathy/minGPT",
        "description": "...",
        "topics": ["gpt", "pytorch"],
        ...
    }
    
    è¾“å‡ºæ ¼å¼ï¼ˆç»Ÿä¸€ï¼‰ï¼š
    {
        "modelId": "karpathy/minGPT",
        "description": "...",
        "task": "text-generation",          # æ–°å¢
        "data_types": ["nlp"],              # æ–°å¢
        "categories": ["llms", "education"] # æ–°å¢
        ...
    }
    """
    # ç»„åˆæ‰€æœ‰æ–‡æœ¬ä¿¡æ¯
    text = " ".join([
        model.get("description", ""),
        model.get("modelId", ""),
        " ".join(model.get("topics", []))
    ])
    
    # æ¨æ–­ä»»åŠ¡
    task = find_task_from_text(text)
    
    # æ ¹æ®ä»»åŠ¡æ¨æ–­æ•°æ®ç±»å‹å’Œé¢†åŸŸ
    data_type = get_data_type_for_task(task)
    categories = get_categories_for_task(task)
    
    # æ·»åŠ æ–°å­—æ®µï¼ˆä¿æŒä¸ HuggingFace æ ¼å¼ä¸€è‡´ï¼‰
    model["task"] = task
    model["data_types"] = [data_type] if data_type else []
    model["categories"] = categories
    
    return model


def map_models(models):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªæ¨¡å‹
    
    å‚æ•°:
        models: GitHub loader è¾“å‡ºçš„æ¨¡å‹åˆ—è¡¨
    
    è¿”å›:
        list: æ·»åŠ äº†åˆ†ç±»ä¿¡æ¯çš„æ¨¡å‹åˆ—è¡¨
    """
    print("\n" + "=" * 60)
    print("ğŸ§© Taxonomy Mapper - å¼€å§‹åˆ†ç±»")
    print("=" * 60)
    
    mapped_models = []
    for i, model in enumerate(models, 1):
        print(f"[{i}/{len(models)}] {model['modelId']}")
        
        mapped = map_taxonomy(model)
        
        print(f"  â†’ Task: {mapped['task']}")
        print(f"  â†’ Data Type: {mapped['data_types']}")
        print(f"  â†’ Categories: {', '.join(mapped['categories'][:3])}")  # åªæ˜¾ç¤ºå‰3ä¸ª
        
        mapped_models.append(mapped)
    
    print("=" * 60)
    print(f"âœ… åˆ†ç±»å®Œæˆï¼")
    print("=" * 60)
    
    return mapped_models


if __name__ == "__main__":
    import json
    from pathlib import Path

    # ä» github_raw_data.json è¯»å–
    input_path = Path(__file__).resolve().parents[1] / "output/github_raw_data.json"
    with open(input_path, "r", encoding="utf-8") as f:
        models = json.load(f)

    # æ‰§è¡Œæ˜ å°„
    mapped = map_models(models)

    # ä¿å­˜ç»“æœ
    output_path = Path(__file__).resolve().parents[1] / "output/github_mapped_data.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(mapped, f, indent=2, ensure_ascii=False)

    print(f"âœ… category_task_save_toï¼š{output_path}")
